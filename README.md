# Neural-Network-Hyperparameter-Optimization-papers
## This repo will give all the papers related to Neural Network Hyperparameter Optimization(Optimal network configuration search) and short video explanation of each paper. In this repo you will find papers relevent to evolution strategies, baysian optimization, Genetic algorithms for configuration search, and recent work on neural architecture search(NAS). 

### 2015 and Before
##### 1. An evolutionary algorithm that constructs recurrent neural networks.[\[Paper\]](https://ieeexplore.ieee.org/document/265960/)
##### 2. Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures.[\[Paper\]]()
##### 3. Algorithms for hyperparameter optimization.[\[Paper\]]()
##### 4. Neuroevolution: from architectures to learning.[\[Paper\]]()
##### 5. A comparative analysis of selection schemes used in genetic algorithms.[\[Paper\]]()
##### 6. Sequential model-based optimization for general algorithm configuration.[\[Paper\]]()
##### 7. Evolving neural networks through augmenting topologies.[\[Paper\]]()
##### 8. A hypercube-based encoding for evolving large-scale neural networks.[\[Paper\]]()
##### 9. Raiders of the lost architecture: Kernels for bayesian optimization in conditional parameter spaces.[\[Paper\]]()
##### 10. Freeze-thaw bayesian optimization.[\[Paper\]]()
##### 11. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves.[\[Paper\]]()
##### 12. Random Search for Hyper-Parameter Optimization.[\[Paper\]]()
##### 13. The evolution of learning algorithms for artificial neural networks.[\[Paper\]]()
##### 14. Evolving dynamical neural networks for adaptive behavior.[\[Paper\]]()
##### 15. Evolving networks: using the genetic algorithm with connectionist learning.[\[Paper\]]()
##### 16. Exploring the T-maze: evolving learning-like robot behaviors using CTRNNs.[\[Paper\]]()
##### 17. Evolving modular genetic regulatory networks.[\[Paper\]]()
##### 18. Evolving spike-timing-dependent plasticity for single-trial learning in robots.[\[Paper\]]()
##### 19. Neuroevolution with Analog Genetic Encoding. In: Parallel problem solving from nature.[\[Paper\]]()
##### 20. Combinations of genetic algorithms and neural networks: A survey of the state of the art.[\[Paper\]]()
##### 21. Generative neuroevolution for deep learning.[\[Paper\]]()

### 2016
##### 1. Network morphism.[\[Paper\]]()
##### 2. Taking the human out of the loop: A review of bayesian optimization.[\[Paper\]]()

### 2017 
##### 1. Connectivity learning in multi-branch networks.[\[Paper\]]()
##### 2. Designing neural network architectures using reinforcement learning.[\[Paper\]]()
##### 3. Accelerating Neural Architecture Search using Performance Prediction.[\[Paper\]]()
##### 4. SMASH: one-shot model architecture search through hypernetworks.[\[Paper\]]()
##### 5. Simple And Efficient Architecture Search for Convolutional Neural Networks.[\[Paper\]]()
##### 6. Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets.[\[Paper\]]()
##### 7. Learning curve prediction with Bayesian neural networks.[\[Paper\]]()
##### 8. Hyperband: bandit-based configuration evaluation for hyperparameter optimization.[\[Paper\]]() 
##### 9. Progressive Neural Architecture Search.[\[Paper\]]()
##### 10. Sgdr: Stochastic gradient descent with warm restarts.[\[Paper\]]()
##### 11. Evolving Deep Neural Networks.[\[Paper\]]()
##### 12. Hypernetworks.[\[Paper\]]()
##### 13. DeepArchitect: Automatically Designing and Training Deep Architectures.[\[Paper\]]()
##### 14. Large-scale evolution of image classifiers.[\[Paper\]]()
##### 15. A genetic programming approach to designing convolutional neural network architectures.[\[Paper\]]()
##### 16. Modularized morphing of neural networks.[\[Paper\]]()
##### 17. Finding Competitive Network Architectures Within a Day Using UCT.[\[Paper\]]() 
##### 18. Genetic CNN.[\[Paper\]]()
##### 19. Neural architecture search with reinforcement learning.[\[Paper\]]()
##### 20. A genetic programming approach to designing convolutional neural network architectures.[\[Paper\]]()

### 2018
##### 1. Path-Level Network Transformation for Efficient Architecture Search.[\[Paper\]]()
##### 2. AutoAugment: Learning Augmentation Policies from Data.[\[Paper\]]()
##### 3. Ppp-net: Platform-aware progressive search for pareto-optimal neural architectures.[\[Paper\]]() 
##### 4. Efficient Multi-objective Neural Architecture Search via Lamarckian Evolution.[\[Paper\]]()
##### 5. BOHB: Robust and efficient hyperparameter optimization at scale.[\[Paper\]]()
##### 6. Towards reproducible neural architecture and hyperparameter search.[\[Paper\]]()
##### 7. Evolutionary Architecture Search For Deep Multitask Networks.[\[Paper\]]()
##### 8. Hierarchical Representations for Efficient Architecture Search. [\[Paper\]]()
##### 9. Darts: Differentiable architecture search.[\[Paper\]]()
##### 10. Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing and Back.[\[Paper\]]()
##### 11. Efficient neural architecture search via parameter sharing.[\[Paper\]]()
##### 12. Dynamic Network Architectures.[\[Paper\]]()
##### 13. From Nodes to Networks: Evolving Recurrent Neural Networks.[\[Paper\]]()
##### 14. Regularized Evolution for Image Classifier Architecture Search.[\[Paper\]]()
##### 15. Differentiable neural network architecture search.[\[Paper\]]()
##### 16. Exploiting the potential of standard convolutional autoencoders for image restoration by evolutionary search.[\[Paper\]]()
##### 17. Towards automated deep learning: Efficient joint neural architecture and hyperparameter search.[\[Paper\]]()
##### 18. Practical Network Blocks Design with Q-Learning.[\[Paper\]]()
##### 19. Resource-efficient neural architect.[\[Paper\]]()
##### 20. Learning transferable architectures for scalable image recognition.[\[Paper\]]()





